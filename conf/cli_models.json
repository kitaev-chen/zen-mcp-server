{
  "_README": {
    "description": "CLI model metadata for clink-backed providers",
    "documentation": "https://github.com/BeehiveInnovations/zen-mcp-server/blob/main/docs/custom_models.md",
    "usage": "Models here route through CLIModelProvider to external CLI agents configured in clink",
    "notes": "CLI models do NOT support API-level thinking_mode. The --thinking flag in CLI configs is a separate concept."
  },
  "models": [
    {
      "model_name": "cli:gemini",
      "aliases": ["gemini cli", "gemini-cli", "gcli"],
      "cli_client": "gemini",
      "friendly_name": "Gemini CLI",
      "intelligence_score": 15,
      "description": "Gemini CLI with 1M context, web search, and tool capabilities",
      "context_window": 1000000,
      "max_output_tokens": 65536,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": false,
      "supports_function_calling": true,
      "supports_json_mode": false,
      "supports_images": true,
      "supports_temperature": false
    },
    {
      "model_name": "cli:claude",
      "aliases": ["claude cli", "claude-cli", "ccli"],
      "cli_client": "claude",
      "friendly_name": "Claude CLI",
      "intelligence_score": 16,
      "description": "Claude CLI (Claude 3.5/4 Sonnet) with code editing and file access",
      "context_window": 200000,
      "max_output_tokens": 64000,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": false,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": true,
      "supports_temperature": false
    },
    {
      "model_name": "cli:codex",
      "aliases": ["codex cli", "codex-cli", "openai cli", "openai-cli", "ocli"],
      "cli_client": "codex",
      "friendly_name": "Codex CLI",
      "intelligence_score": 15,
      "description": "OpenAI Codex CLI (gpt-5/gpt-5-codex) for code generation",
      "context_window": 200000,
      "max_output_tokens": 32768,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": false,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": false,
      "supports_temperature": false
    },
    {
      "model_name": "cli:kimi",
      "aliases": ["kimi cli", "kimi-cli", "moonshot cli", "moonshot-cli", "kcli"],
      "cli_client": "kimi",
      "friendly_name": "Kimi CLI",
      "intelligence_score": 14,
      "description": "Kimi CLI (Moonshot K2, --thinking is not enabled in clink config)",
      "context_window": 262144,
      "max_output_tokens": 65536,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": false,
      "supports_function_calling": true,
      "supports_json_mode": false,
      "supports_images": false,
      "supports_temperature": false
    },
    {
      "model_name": "cli:qwen",
      "aliases": ["qwen cli", "qwen-cli", "tongyi cli", "tongyi-cli", "qcli"],
      "cli_client": "qwen",
      "friendly_name": "Qwen CLI",
      "intelligence_score": 13,
      "description": "Qwen CLI (Qwen3-max/code-plus) from Alibaba with 1M context",
      "context_window": 1000000,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": false,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_images": true,
      "supports_temperature": false
    },
    {
      "model_name": "cli:vecli",
      "aliases": ["vecli", "doubao cli", "doubao-cli", "vcli"],
      "cli_client": "vecli",
      "friendly_name": "Vecli",
      "intelligence_score": 12,
      "description": "Volcengine CLI for ByteDance Doubao-1.5-pro",
      "context_window": 256000,
      "max_output_tokens": 16384,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": false,
      "supports_function_calling": true,
      "supports_json_mode": false,
      "supports_images": false,
      "supports_temperature": false
    },
    {
      "model_name": "cli:iflow",
      "aliases": ["iflow cli", "iflow-cli", "icli"],
      "cli_client": "iflow",
      "friendly_name": "iFlow CLI",
      "intelligence_score": 11,
      "description": "iFlow CLI for many models with 1M+ context",
      "context_window": 1000000,
      "max_output_tokens": 64000,
      "supports_extended_thinking": false,
      "supports_system_prompts": true,
      "supports_streaming": false,
      "supports_function_calling": true,
      "supports_json_mode": false,
      "supports_images": false,
      "supports_temperature": false
    }
  ]
}
